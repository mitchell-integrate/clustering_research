{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataReader(object):\n",
    "\n",
    "    def __init__(self,X,batch_size=1):\n",
    "        self.X = X\n",
    "        self.num_examples = X.shape[0]\n",
    "        self.batch_number = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = int(np.ceil(X.shape[0] / batch_size))\n",
    "\n",
    "    def next_batch(self):\n",
    "        low_ix = self.batch_number*self.batch_size\n",
    "        up_ix = (self.batch_number + 1)*self.batch_size\n",
    "        if up_ix >= self.X.shape[0]:\n",
    "            up_ix = self.X.shape[0]\n",
    "            self.batch_number = 0 # reset batch_number to zero\n",
    "        else:\n",
    "            self.batch_number = self.batch_number + 1\n",
    "        return self.X[low_ix:up_ix,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving NBA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_PLAYER_STATS_QUERY = \"\"\"SELECT \n",
    "    player_id, \n",
    "    game_id,\n",
    "    FGM, \n",
    "    FGA, \n",
    "    3PM, \n",
    "    3PA, \n",
    "    FTM, \n",
    "    FTA, \n",
    "    OREB, \n",
    "    DREB, \n",
    "    AST, \n",
    "    TOV, \n",
    "    STL, \n",
    "    BLK, \n",
    "    PF, \n",
    "    PM\n",
    "FROM regboxscores WHERE MIN > 0;\"\"\"\n",
    "PLAYERS_QUERY = \"\"\"SELECT code_name, id FROM players\"\"\"\n",
    "GAMES_QUERY = \"\"\"SELECT id, dt FROM reggames\"\"\"\n",
    "\n",
    "engine = create_engine('mysql+pymysql://root:beer@localhost/nba')\n",
    "raw_box_scores = pd.read_sql_query(AVG_PLAYER_STATS_QUERY, con = engine)\n",
    "raw_players = pd.read_sql_query(PLAYERS_QUERY, con = engine)\n",
    "raw_games = pd.read_sql_query(GAMES_QUERY, con = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "box_scores = raw_box_scores.dropna().copy()\n",
    "players = raw_players.dropna().copy()\n",
    "games = raw_games.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "box_scores = box_scores.merge(games, left_on='game_id', right_on='id', how='inner')\n",
    "box_scores = box_scores.drop('id', 1)\n",
    "box_scores = box_scores.drop('game_id', 1)\n",
    "box_scores = players.merge(box_scores, left_on='id', right_on='player_id', how='inner')\n",
    "box_scores = box_scores.drop('id', 1)\n",
    "\n",
    "box_scores['dt'] = pd.to_datetime(box_scores['dt'])\n",
    "\n",
    "box_scores['dt'] = np.where(box_scores['dt'].dt.month >= 10,\n",
    "                            box_scores['dt'].dt.year,\n",
    "                            box_scores['dt'].dt.year - 1)\n",
    "\n",
    "box_scores['code_name'] = box_scores['code_name'].astype(str) + ' (' + box_scores['dt'].astype(str) + '-' + (box_scores['dt'] + 1).astype(str) + ')'\n",
    "box_scores = box_scores.drop('dt', 1)\n",
    "box_scores = box_scores.groupby('code_name').mean().reset_index()\n",
    "box_scores['player_id'] = box_scores['player_id'].astype(int)\n",
    "\n",
    "df1 = box_scores.iloc[:, :2] # player ids + names\n",
    "df2 = box_scores.iloc[:, 2:] # features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, n_hidden2, n_epochs):\n",
    "    n_inputs = 14\n",
    "    n_hidden1 = 14\n",
    "    n_hidden3 = n_hidden1\n",
    "    n_outputs = n_inputs\n",
    "    learning_rate = 0.01\n",
    "    l2_reg = 0.001\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "    with tf.contrib.framework.arg_scope(\n",
    "            [fully_connected],\n",
    "            activation_fn=tf.nn.elu,\n",
    "            weights_initializer=tf.contrib.layers.variance_scaling_initializer(),\n",
    "            weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg)):\n",
    "        hidden1 = fully_connected(X, n_hidden1)\n",
    "        hidden2 = fully_connected(hidden1, n_hidden2)\n",
    "        hidden3 = fully_connected(hidden2, n_hidden3)\n",
    "        outputs = fully_connected(hidden3, n_outputs, activation_fn=None)\n",
    "\n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([reconstruction_loss] + reg_losses)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "    batch_size = 70\n",
    "\n",
    "    data_reader = dataReader(data, batch_size)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "            n_batches = data_reader.num_batches\n",
    "            for iteration in range(n_batches):\n",
    "\n",
    "                X_batch = data_reader.next_batch()\n",
    "                sess.run(training_op, feed_dict={X: X_batch})\n",
    "        print('d=' + str(n_hidden2) +', ' + 'loss: ' + str(loss.eval(feed_dict={X: data})))\n",
    "        return pd.DataFrame(outputs.eval(feed_dict={X: data})), pd.DataFrame(hidden2.eval(feed_dict={X: data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_cluster(data, col_name):\n",
    "    km = KMeans(n_clusters=5).fit(data)\n",
    "    labels = km.labels_\n",
    "    df = pd.DataFrame([labels]).T # TODO: is transpose needed?\n",
    "    df.columns = [col_name]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with different dimensionalities for 2nd hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_box = df2.values\n",
    "\n",
    "outputs_1, hidden_1 = train_model(X_box, 1, 50)\n",
    "outputs_2, hidden_2 = train_model(X_box, 2, 50)\n",
    "outputs_5, hidden_5 = train_model(X_box, 5, 50)\n",
    "outputs_10, hidden_10 = train_model(X_box, 10, 50)\n",
    "outputs_14, hidden_14 = train_model(X_box, 14, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create clusterings for the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.concat([df1,\n",
    "                     kmeans_cluster(hidden_1, 'Bucket (d=1)'),\n",
    "                     kmeans_cluster(hidden_2, 'Bucket (d=2)'),\n",
    "                     kmeans_cluster(hidden_5, 'Bucket (d=5)'),\n",
    "                     kmeans_cluster(hidden_10, 'Bucket (d=10)'),\n",
    "                     kmeans_cluster(hidden_14, 'Bucket (d=14)'),\n",
    "                     kmeans_cluster(df2, 'Bucket (original)')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = results[['player_id', 'Bucket (original)']].groupby(['Bucket (original)']).count().plot(kind='bar',\n",
    "              title =\"K-Means Clustering of Original Data\", \n",
    "              figsize=(8, 5),\n",
    "              legend=False,\n",
    "              fontsize=12)\n",
    "ax.set_xlabel(\"Bucket\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of Players\", fontsize=12)\n",
    "plt.xticks(rotation=360)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = results[['player_id', 'Bucket (d=14)']].groupby(['Bucket (d=14)']).count().plot(kind='bar', \n",
    "              title =\"K-Means Clustering of d=14 Data\",\n",
    "              figsize=(8, 5),\n",
    "              legend=False,\n",
    "              fontsize=12)\n",
    "ax.set_xlabel(\"Bucket\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of Players\", fontsize=12)\n",
    "plt.xticks(rotation=360)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# have to do this again because kmeans function doesn't return x and y -- should change that\n",
    "km = KMeans(n_clusters=5).fit(hidden_2)\n",
    "labels = km.labels_\n",
    "df = pd.DataFrame([labels]).T # TODO: is transpose needed?\n",
    "df.columns = ['d=2']\n",
    "new = pd.concat([results, df, hidden_2], axis=1)\n",
    "new = new.drop('Bucket (d=2)', 1)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(new[0],new[1],c=new['d=2'],alpha=0.5)\n",
    "plt.annotate('steph curry (15-16)', (new[0][1562], new[1][1562]))\n",
    "plt.annotate('kobe bryant (02-03)', (new[0][1009], new[1][1009]))\n",
    "plt.annotate('michael jordan (02-03)', (new[0][3698], new[1][3698]))\n",
    "plt.annotate('shaq (01-02)', (new[0][5051], new[1][5051]))\n",
    "plt.annotate('james young (15-16)', (new[0][7274], new[1][7274]))\n",
    "plt.annotate('yao ming (10-11)', (new[0][7266], new[1][7266]))\n",
    "plt.annotate('rick fox (01-02)', (new[0][2223], new[1][2223]))\n",
    "plt.annotate('reggie williams (09-10)', (new[0][7123], new[1][7123]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rand_index(df, col_1, col_2):\n",
    "    n11 = 0\n",
    "    n00 = 0\n",
    "    # TODO: better loop iteration\n",
    "    for i in df.index:\n",
    "        for j in df.index:\n",
    "            if j <= i:\n",
    "                continue\n",
    "            x1 = df.iloc[i, col_1]\n",
    "            x2 = df.iloc[j, col_1]\n",
    "            y1 = df.iloc[i, col_2]\n",
    "            y2 = df.iloc[j, col_2]\n",
    "            if x1 == x2 and y1 == y2:\n",
    "                n11 += 1\n",
    "            elif not x1 == x2 and not y1 == y2:\n",
    "                n00 += 1\n",
    "    return 2 * (n11 + n00) / (len(results) * (len(results) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jaccard_index(df, col_1, col_2):\n",
    "    n11 = 0\n",
    "    n10 = 0\n",
    "    n01 = 0\n",
    "    # TODO: better loop iteration\n",
    "    for i in df.index:\n",
    "        for j in df.index:\n",
    "            if j <= i:\n",
    "                continue\n",
    "            x1 = df.iloc[i, col_1]\n",
    "            x2 = df.iloc[j, col_1]\n",
    "            y1 = df.iloc[i, col_2]\n",
    "            y2 = df.iloc[j, col_2]\n",
    "            if x1 == x2 and y1 == y2:\n",
    "                n11 += 1\n",
    "            elif x1 == x2 and not y1 == y2:\n",
    "                n10 += 1\n",
    "            elif not x1 == x2 and y1 == y2:\n",
    "                n01 += 1\n",
    "    return n11 / (n11 + n10 + n01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    print(calculate_rand_index(results, col, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    print(calculate_jaccard_index(results, col, 7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
